{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basic Extract, Transform and Load (ETL) pipeline using web scrapping, pandas and sql lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from io import StringIO #Converts HTML table content (as a string) into a file-like object so that pandas.read_html() can parse it directly\n",
    "import requests  #A Python library for making HTTP requests to access web resources like HTML pages, APIs, etc\n",
    "from bs4 import BeautifulSoup #A library for parsing HTML and XML documents. It helps extract specific elements from a web page\n",
    "import pandas as pd  #A powerful library for data manipulation and analysis.\n",
    "import sqlite3 #data base use for small amount of data\n",
    "from datetime import datetime  #Provides functions for working with dates and times using it for logs currently\n",
    "import os   #Provides a way to interact with the operating system, such as checking if directories exist or creating new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Maintaining a Log File\n",
    "This step is done to record the logs while performing ETL and it is not neccessary in an ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log progress messages with timestamps\n",
    "def log_progress(message):\n",
    "    \"\"\"This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. Function returns nothing\"\"\"\n",
    "    \n",
    "    # Check if the 'logs' directory exists, create it if not\n",
    "    log_dir = './logs'\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    # Open the log file in append mode and write the message with timestamp\n",
    "    with open(os.path.join(log_dir, 'code_log.txt'), 'a') as f:\n",
    "        f.write(f'{datetime.now()}: {message}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from the webpage\n",
    "def extract(url, table_attribs):\n",
    "    \"\"\" This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Send HTTP request to the URL and check for successful response\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for bad responses\n",
    "        \n",
    "        # Parse the page content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Locate the table based on the given attribute ('By market capitalization') and extract it\n",
    "        table = soup.find('span', string=table_attribs).find_next('table')\n",
    "        \n",
    "        # Convert the HTML table to a pandas DataFrame\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        \n",
    "        # Log progress of data extraction\n",
    "        log_progress('Data extraction complete. Initiating Transformation process')\n",
    "        \n",
    "        # Return the DataFrame for further processing\n",
    "        return df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # If there's an issue with the request, log the error\n",
    "        log_progress(f'Error during web scraping: {e}')\n",
    "        raise  # Re-raise the exception after logging it\n",
    "    except Exception as e:\n",
    "        # If any other error occurs, log it\n",
    "        log_progress(f'Error in extract function: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform the extracted data using exchange rates\n",
    "def transform(df, csv_path):\n",
    "    \"\"\" This function get the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of the Market Cap column to\n",
    "    respective currencies \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Read the exchange rates CSV and convert it into a dictionary it will store the cvs data into dictionary\n",
    "        exchange_rate = pd.read_csv(csv_path, index_col=0).to_dict()['Rate']\n",
    "        \n",
    "        # Convert 'Market cap (US$ billion)' into GBP, EUR, and INR using the exchange rates\n",
    "        df['MC_GBP_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['GBP'], 2)\n",
    "        df['MC_EUR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['EUR'], 2)\n",
    "        df['MC_INR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['INR'], 2)\n",
    "\n",
    "        # Print a specific value for debugging purposes (5th row, index 4)\n",
    "        print(df['MC_EUR_Billion'][4])\n",
    "\n",
    "        # Log the completion of the transformation process\n",
    "        log_progress('Data transformation complete. Initiating Loading process')\n",
    "\n",
    "        # Return the transformed DataFrame\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        # If any error occurs during transformation, log it\n",
    "        log_progress(f'Error in transform function: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the transformed data to a CSV file\n",
    "def load_to_csv(df, output_path):\n",
    "    \"\"\" This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Save the DataFrame to CSV without including the index column\n",
    "        df.to_csv(output_path, index=False)\n",
    "        \n",
    "        # Log that the data has been saved successfully\n",
    "        log_progress('Data saved to CSV file')\n",
    "    except Exception as e:\n",
    "        # If there's an error saving to CSV, log it\n",
    "        log_progress(f'Error saving data to CSV: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the transformed data into an SQLite database\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    \"\"\" This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Save the DataFrame to the specified database table, replacing it if it exists\n",
    "        df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "        \n",
    "        # Log that the data has been successfully loaded into the database\n",
    "        log_progress('Data loaded to Database as a table, Executing queries')\n",
    "    except Exception as e:\n",
    "        # If there's an error loading to the database, log it\n",
    "        log_progress(f'Error loading data to database: {e}')\n",
    "        raise\n",
    "\n",
    "# Function to run SQL queries on the database\n",
    "def run_query(query_statement, sql_connection):\n",
    "    \"\"\" This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create a cursor object to interact with the database\n",
    "        cursor = sql_connection.cursor()\n",
    "        \n",
    "        # Execute the provided SQL query\n",
    "        cursor.execute(query_statement)\n",
    "        \n",
    "        # Fetch all results of the query\n",
    "        result = cursor.fetchall()\n",
    "        \n",
    "        # Log that the query execution is complete\n",
    "        log_progress('Process Complete')\n",
    "        \n",
    "        # Return the result of the query\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # If there's an error running the query, log it\n",
    "        log_progress(f'Error running query: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                Bank name  Market cap (US$ billion)\n",
      "0     1                           JPMorgan Chase                    432.92\n",
      "1     2                          Bank of America                    231.52\n",
      "2     3  Industrial and Commercial Bank of China                    194.56\n",
      "3     4               Agricultural Bank of China                    160.68\n",
      "4     5                                HDFC Bank                    157.91\n",
      "153.17\n",
      "[(1, 'JPMorgan Chase', 432.92, 346.34, 419.93, 36798.2), (2, 'Bank of America', 231.52, 185.22, 224.57, 19679.2), (3, 'Industrial and Commercial Bank of China', 194.56, 155.65, 188.72, 16537.6), (4, 'Agricultural Bank of China', 160.68, 128.54, 155.86, 13657.8), (5, 'HDFC Bank', 157.91, 126.33, 153.17, 13422.35), (6, 'Wells Fargo', 155.87, 124.7, 151.19, 13248.95), (7, 'HSBC Holdings PLC', 148.9, 119.12, 144.43, 12656.5), (8, 'Morgan Stanley', 140.83, 112.66, 136.61, 11970.55), (9, 'China Construction Bank', 139.82, 111.86, 135.63, 11884.7), (10, 'Bank of China', 136.81, 109.45, 132.71, 11628.85)]\n",
      "[(151.987,)]\n",
      "[('JPMorgan Chase',), ('Bank of America',), ('Industrial and Commercial Bank of China',), ('Agricultural Bank of China',), ('HDFC Bank',)]\n"
     ]
    }
   ],
   "source": [
    "# Main execution block\n",
    "if __name__ == '__main__':\n",
    "    # Define URL, output paths, and database connection details\n",
    "    url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "    output_csv_path = './output/Converted_exchange_rates_data.csv'\n",
    "    database_name = './output/file.db'\n",
    "    table_name = 'Conversations'\n",
    "    \n",
    "    # Log the start of the ETL process\n",
    "    log_progress('Preliminaries complete. Initiating ETL process')\n",
    "    \n",
    "    try:\n",
    "        # Extract data from the web\n",
    "        df = extract(url, 'By market capitalization')\n",
    "        \n",
    "        # Print the first few rows of the extracted data\n",
    "        print(df.head())\n",
    "        \n",
    "        # Transform the data using exchange rates\n",
    "        df = transform(df, './input/exchange_rate.csv')\n",
    "        \n",
    "        # Load the transformed data to a CSV file\n",
    "        load_to_csv(df, output_csv_path)\n",
    "        \n",
    "        # Connect to the SQLite database and load data into it\n",
    "        with sqlite3.connect(database_name) as conn:\n",
    "            # Load data into the database\n",
    "            load_to_db(df, conn, table_name)\n",
    "            \n",
    "            # Run SQL queries to fetch results from the database and print them\n",
    "            print(run_query('SELECT * FROM Conversations', conn))\n",
    "            print(run_query('SELECT AVG(MC_GBP_Billion) FROM Conversations', conn))\n",
    "            print(run_query('SELECT \"Bank name\" FROM Conversations LIMIT 5', conn))\n",
    "\n",
    "    except Exception as e:\n",
    "        # If there's an error in the ETL process, log it and print the message\n",
    "        log_progress(f'Error in ETL process: {e}')\n",
    "        print(f\"Error during the process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
