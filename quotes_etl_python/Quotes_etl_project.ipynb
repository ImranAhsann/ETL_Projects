{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8851f457-610b-4c52-bdf4-ba3f74bfddad",
   "metadata": {},
   "source": [
    "### Web Scraping, Data Transformation, and Loading using Python (ETL Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d50746e5-7d6f-4d7e-9dcd-a5abe72a125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched page 1\n",
      "Successfully fetched page 2\n",
      "Successfully fetched page 3\n",
      "Successfully fetched page 4\n",
      "Successfully fetched page 5\n",
      "Data saved to SQLite database.\n",
      "Data saved to CSV file.\n",
      "ETL Process Completed!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Scraping Data (Extract) from multiple pages\n",
    "base_url = 'http://quotes.toscrape.com/page/{}/'\n",
    "page_num = 1  # Start from page 1\n",
    "quotes_data = []\n",
    "\n",
    "# Loop through the first 5 pages (you can change this to scrape more pages)\n",
    "for page_num in range(1, 6):\n",
    "    url = base_url.format(page_num)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully fetched page {page_num}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page_num}, status code: {response.status_code}\")\n",
    "        continue\n",
    "    \n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract quotes, authors, and tags\n",
    "    quotes = soup.find_all('div', class_='quote')\n",
    "    \n",
    "    for quote in quotes:\n",
    "        text = quote.find('span', class_='text').get_text()  # Extract quote text\n",
    "        author = quote.find('small', class_='author').get_text()  # Extract author name\n",
    "        tags = [tag.get_text() for tag in quote.find_all('a', class_='tag')]  # Extract tags\n",
    "        \n",
    "        # Append the data to the list\n",
    "        quotes_data.append([text, author, ', '.join(tags)])\n",
    "\n",
    "# Step 2: Transform Data (Create a DataFrame)\n",
    "df = pd.DataFrame(quotes_data, columns=['Quote', 'Author', 'Tags'])\n",
    "\n",
    "# Step 3: Load Data (Save to SQLite and CSV)\n",
    "\n",
    "# Save data to SQLite database\n",
    "conn = sqlite3.connect('./output/quotes_data.db')\n",
    "df.to_sql('quotes', conn, if_exists='replace', index=False)\n",
    "print(\"Data saved to SQLite database.\")\n",
    "\n",
    "# Save data to CSV\n",
    "df.to_csv('./output/quotes_data.csv', index=False)\n",
    "print(\"Data saved to CSV file.\")\n",
    "\n",
    "# Close SQLite connection\n",
    "conn.close()\n",
    "\n",
    "print(\"ETL Process Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd3de8-4790-4def-aab2-73f1bbe84b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
